# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ct8sCQf2EtXtiufEINZJ9V5rpJeLc17V
"""

import pandas as pd

df = pd.read_csv('Life_Expectancy_Data.csv')

print("First 5 rows of the DataFrame:")
print(df.head())

print("\nConcise summary of the DataFrame:")
df.info()

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 1. Clean the column names
df.columns = [col.strip() for col in df.columns]
print("Cleaned column names:")
print(df.columns)

# 2. Check for missing values
missing_values = df.isnull().sum()
print("\nSum of missing values for each column:")
print(missing_values[missing_values > 0])

# Separate numerical and categorical columns
numerical_cols = df.select_dtypes(include=np.number).columns.tolist()
categorical_cols = df.select_dtypes(include='object').columns.tolist()

# Identify columns with missing values
missing_numerical_cols = [col for col in numerical_cols if missing_values[col] > 0]
missing_categorical_cols = [col for col in categorical_cols if missing_values[col] > 0]

# 3. Impute missing numerical values with the mean
for col in missing_numerical_cols:
    df[col].fillna(df[col].mean(), inplace=True)
print("\nMissing numerical values imputed with mean.")

# 4. Impute missing categorical values with the mode (if any)
for col in missing_categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)
print("Missing categorical values imputed with mode (if any).")

# Verify no more missing values
print("\nMissing values after imputation:")
print(df.isnull().sum()[df.isnull().sum() > 0])

# 5. Drop the 'Country' column
df.drop('Country', axis=1, inplace=True)
print("\n'Country' column dropped.")

# 6. Convert the 'Status' column into numerical format using one-hot encoding
df = pd.get_dummies(df, columns=['Status'], drop_first=True)
print("\n'Status' column one-hot encoded.")
print("DataFrame head after one-hot encoding:")
print(df.head())

# 7. Define features (X) and target variable (y)
y = df['Life expectancy']
X = df.drop('Life expectancy', axis=1)

print("\nShape of features (X):", X.shape)
print("Shape of target (y):", y.shape)

# 8. Instantiate StandardScaler
scaler = StandardScaler()

# 9. Apply the scaler to the feature DataFrame X
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
print("\nFeatures scaled using StandardScaler.")
print("Scaled features head:")
print(X_scaled.head())

# 10. and 11. Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print("\nData split into training and testing sets:")
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""Train Linear Regression Model"""

from sklearn.linear_model import LinearRegression

# Instantiate the Linear Regression model
linear_model = LinearRegression()

# Fit the model to the training data
linear_model.fit(X_train, y_train)

print("Linear Regression model trained successfully.")

"""Train Ridge Regression Model"""

from sklearn.linear_model import Ridge

# Instantiate the Ridge Regression model
ridge_model = Ridge(random_state=42)

# Fit the model to the training data
ridge_model.fit(X_train, y_train)

print("Ridge Regression model trained successfully.")

"""Train Lasso Regression Model"""

from sklearn.linear_model import Lasso

# Instantiate the Lasso Regression model
lasso_model = Lasso(random_state=42)

# Fit the model to the training data
lasso_model.fit(X_train, y_train)

print("Lasso Regression model trained successfully.")

"""Evaluate Models"""

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Make predictions on the test set
y_pred_linear = linear_model.predict(X_test)
y_pred_ridge = ridge_model.predict(X_test)
y_pred_lasso = lasso_model.predict(X_test)

# Function to calculate and print metrics
def evaluate_model(model_name, y_true, y_pred):
    r2 = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    return {"R-squared": r2, "MAE": mae, "RMSE": rmse}

# Evaluate each model
metrics = {
    "Linear Regression": evaluate_model("Linear Regression", y_test, y_pred_linear),
    "Ridge Regression": evaluate_model("Ridge Regression", y_test, y_pred_ridge),
    "Lasso Regression": evaluate_model("Lasso Regression", y_test, y_pred_lasso)
}

# Print the metrics
print("Model Evaluation Metrics:")
for model_name, model_metrics in metrics.items():
    print(f"\n{model_name}:")
    for metric_name, value in model_metrics.items():
        print(f"  {metric_name}: {value:.4f}")

"""Visualize Model Performance"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Convert metrics dictionary to a DataFrame
metrics_df = pd.DataFrame(metrics).T
metrics_df.index.name = 'Model'
print("Metrics DataFrame (wide format):")
print(metrics_df)

# Melt the DataFrame to a long format
metrics_melted = metrics_df.reset_index().melt(id_vars='Model', var_name='Metric', value_name='Value')
print("\nMetrics DataFrame (long format):")
print(metrics_melted.head())

# Get unique metrics to iterate through
metrics_list = metrics_melted['Metric'].unique()

# Set up the matplotlib figure and axes
fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False)
fig.suptitle('Model Performance Comparison', fontsize=16)

# Plot each metric
for i, metric_name in enumerate(metrics_list):
    sns.barplot(
        x='Model',
        y='Value',
        data=metrics_melted[metrics_melted['Metric'] == metric_name],
        ax=axes[i],
        palette='viridis'
    )
    axes[i].set_title(f'Model {metric_name} Comparison')
    axes[i].set_xlabel('Model')
    axes[i].set_ylabel(metric_name)

plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent overlap, especially for suptitle
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Convert metrics dictionary to a DataFrame
metrics_df = pd.DataFrame(metrics).T
metrics_df.index.name = 'Model'
print("Metrics DataFrame (wide format):")
print(metrics_df)

# Melt the DataFrame to a long format
metrics_melted = metrics_df.reset_index().melt(id_vars='Model', var_name='Metric', value_name='Value')
print("\nMetrics DataFrame (long format):")
print(metrics_melted.head())

# Get unique metrics to iterate through
metrics_list = metrics_melted['Metric'].unique()

# Set up the matplotlib figure and axes
fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False)
fig.suptitle('Model Performance Comparison', fontsize=16)

# Plot each metric
for i, metric_name in enumerate(metrics_list):
    sns.barplot(
        x='Model',
        y='Value',
        data=metrics_melted[metrics_melted['Metric'] == metric_name],
        ax=axes[i],
        palette='viridis',
        hue='Model', # Assign hue to 'Model' as suggested by the warning
        legend=False # Set legend to False to avoid redundant legends if hue is used
    )
    axes[i].set_title(f'Model {metric_name} Comparison')
    axes[i].set_xlabel('Model')
    axes[i].set_ylabel(metric_name)

plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent overlap, especially for suptitle
plt.show()

